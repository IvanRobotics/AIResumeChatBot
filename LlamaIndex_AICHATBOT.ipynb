{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanRobotics/AIResumeChatBot/blob/main/LlamaIndex_AICHATBOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnB3NleMh9Kl"
      },
      "outputs": [],
      "source": [
        "# !pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q0Db4C2AONS"
      },
      "outputs": [],
      "source": [
        "# !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-psS8nB5qyK",
        "outputId": "8ac7bb42-5504-462e-9cd0-4e480da4c4c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2kxK55NBQdQ",
        "outputId": "9ad4de68-7d90-42e9-ee28-22ff425171b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI_Projects/Deep_Learning/AI Chatbot LlamaIndex\n"
          ]
        }
      ],
      "source": [
        "#check the current directory\n",
        "import os\n",
        "current_path = os.getcwd()\n",
        "target_path = '/content/drive/MyDrive/AI_Projects/Deep_Learning/AI Chatbot LlamaIndex'\n",
        "if current_path != target_path:\n",
        "  os.chdir('/content/drive/MyDrive/AI_Projects/Deep_Learning/AI Chatbot LlamaIndex')\n",
        "\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE0pDP6eBRGa",
        "outputId": "47e3001b-4ef4-492c-99c5-b264cfa0ff75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.6.23)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.27.8)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.8)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (0.5.8)\n",
            "Requirement already satisfied: langchain>=0.0.154 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (0.0.198)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (2.0.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (8.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: typing-inspect==0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect==0.8.0->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 3)) (3.8.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (1.6.2)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (5.3.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (6.6.0)\n",
            "Requirement already satisfied: packaging<24,>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (23.1)\n",
            "Requirement already satisfied: pillow<10,>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (8.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (9.0.0)\n",
            "Requirement already satisfied: pympler<2,>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: rich<14,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (13.3.4)\n",
            "Requirement already satisfied: toml<2 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<5,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (4.3)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (0.20.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (3.1.31)\n",
            "Requirement already satisfied: pydeck<1,>=0.1.dev5 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (6.3.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3->streamlit->-r requirements.txt (line 5)) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit->-r requirements.txt (line 5)) (3.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: langchainplus-sdk>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index->-r requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index->-r requirements.txt (line 1)) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index->-r requirements.txt (line 1)) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index->-r requirements.txt (line 1)) (1.10.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 3)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index->-r requirements.txt (line 1)) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index->-r requirements.txt (line 1)) (1.5.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index->-r requirements.txt (line 1)) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2->streamlit->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit->-r requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit->-r requirements.txt (line 5)) (2.14.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal<5,>=1.1->streamlit->-r requirements.txt (line 5)) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators<1,>=0.2->streamlit->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-index->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit->-r requirements.txt (line 5)) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 5)) (2.1.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 5)) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.11.0->streamlit->-r requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit->-r requirements.txt (line 5)) (2023.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qcRH6adiXC4"
      },
      "source": [
        "SimpleDirectoryReader is one of the file loaders in LlamaIndex toolsets. It supports loading multiple files under the folder user provides, in this case, it’s sub-folder ‘./data/’. This magic loader function can support parsing various file types such as .pdf, .jpg, .png, .docx, etc. so we don't need to convet the image files before processing it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_cmSPXqipa5"
      },
      "source": [
        "# Step 1: Loading files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhKL2q-yiEzs"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "data_directory = '/content/drive/MyDrive/AI_Projects/Deep_Learning/AI Chatbot LlamaIndex'\n",
        "\n",
        "reader = SimpleDirectoryReader(data_directory, recursive=True, exclude_hidden=True)\n",
        "documents = reader.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJmMK5fI2R56"
      },
      "outputs": [],
      "source": [
        "# from llama_index import download_loader\n",
        "\n",
        "# WikipediaReader = download_loader(\"WikipediaReader\")\n",
        "# loader = WikipediaReader()\n",
        "# documents = loader.load_data(pages=['Supervised_learning'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7BKfWRJBDBr",
        "outputId": "eb326600-eabf-4511-a07d-11ea2ee24f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('/content/drive/MyDrive/AI_Projects/Deep_Learning/AI Chatbot LlamaIndex/config.env')\n",
        "\n",
        "# Access the variables\n",
        "openai_key = os.getenv('OPENAI_API_KEY')\n",
        "print(openai_key)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RWYJXGQ5GXC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAasOEy5TLx0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = openai_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePCln8sujFO0"
      },
      "source": [
        "# Step 2: Construct Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "591HJfW1jIYh"
      },
      "outputs": [],
      "source": [
        "from llama_index import LLMPredictor, GPTVectorStoreIndex, PromptHelper, ServiceContext\n",
        "from langchain import OpenAI\n",
        "\n",
        "\n",
        "# define LLM\n",
        "openai.api_key = openai_key\n",
        "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-002\"))\n",
        "\n",
        "max_input_size = 4096\n",
        "num_output = 256\n",
        "max_chunk_overlap = 0.2\n",
        "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
        "\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
        "\n",
        "index =  GPTVectorStoreIndex.from_documents(\n",
        "    documents, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb7Au3HI2GwH"
      },
      "source": [
        "# Step3: Query responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_lJIBdt2Bvq",
        "outputId": "af52bbe1-b468-410d-ab4d-84625c303f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ivan Xie has worked for Cornell University, Tesla, and Artobotics. At Cornell University, he worked as a Big Data Analytic Graduate Researcher. He was responsible for developing and maintaining a XGBoost model on AWS SageMaker for hotel bookings and cancellations. He also centralized 1M hotel guest data for analytics and metrics on Tableau to support divisional leaders and business units. At Tesla, he worked as an Automation Engineer Intern. He delivered measurement recommendations and technical specifications for analytics tracking on solar panel production lines. He also deployed models as proofs of concept to optimize the data flow among manufacturing lines to increase efficiency by 15%. At Artobotics, he worked as a Machine Learning Engineer II. He partnered with a major Retail company to address COVID impact on sales volume and recommended risk mitigation strategies with data science solutions such as Supply Chain Optimization, Sentiment Analysis and etc.\n"
          ]
        }
      ],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query('Tell me about all the companies he worked for, and tell me what he did in the second work experience')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Code"
      ],
      "metadata": {
        "id": "5r5jP3xUC3CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "import streamlit as st\n",
        "from llama_index import download_loader\n",
        "from llama_index.node_parser import SimpleNodeParser\n",
        "from llama_index import GPTVectorStoreIndex\n",
        "from llama_index import LLMPredictor, PromptHelper, ServiceContext\n",
        "from langchain import OpenAI\n",
        "\n",
        "doc_path = '/content/drive/MyDrive/AI_Projects/Deep_Learning/AI Chatbot LlamaIndex/config.env'\n",
        "index_file = 'index.json'\n",
        "\n",
        "if 'response' not in st.session_state:\n",
        "    st.session_state.response = ''\n",
        "\n",
        "def send_click():\n",
        "    st.session_state.response  = index.query(st.session_state.prompt)\n",
        "\n",
        "index = None\n",
        "st.title(\"AI Resume Chatbot\")\n",
        "\n",
        "sidebar_placeholder = st.sidebar.container()\n",
        "uploaded_file = st.file_uploader(\"Choose a file\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "\n",
        "    doc_files = os.listdir(doc_path)\n",
        "    for doc_file in doc_files:\n",
        "        os.remove(doc_path + doc_file)\n",
        "\n",
        "    bytes_data = uploaded_file.read()\n",
        "    with open(f\"{doc_path}{uploaded_file.name}\", 'wb') as f: \n",
        "        f.write(bytes_data)\n",
        "\n",
        "    SimpleDirectoryReader = download_loader(\"SimpleDirectoryReader\")\n",
        "\n",
        "    loader = SimpleDirectoryReader(doc_path, recursive=True, exclude_hidden=True)\n",
        "    documents = loader.load_data()\n",
        "    sidebar_placeholder.header('Current Processing Document:')\n",
        "    sidebar_placeholder.subheader(uploaded_file.name)\n",
        "    sidebar_placeholder.write(documents[0].get_text()[:10000]+'...')\n",
        "\n",
        "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
        "\n",
        "    max_input_size = 4096\n",
        "    num_output = 256\n",
        "    max_chunk_overlap = 0.2\n",
        "    prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
        "\n",
        "    index = GPTVectorStoreIndex.from_documents(\n",
        "        documents, service_context=service_context\n",
        "    )\n",
        "\n",
        "    index.save_to_disk(index_file)\n",
        "\n",
        "elif os.path.exists(index_file):\n",
        "    index = GPTVectorStoreIndex.load_from_disk(index_file)\n",
        "\n",
        "    SimpleDirectoryReader = download_loader(\"SimpleDirectoryReader\")\n",
        "    loader = SimpleDirectoryReader(doc_path, recursive=True, exclude_hidden=True)\n",
        "    documents = loader.load_data()\n",
        "    doc_filename = os.listdir(doc_path)[0]\n",
        "    sidebar_placeholder.header('Current Processing Document:')\n",
        "    sidebar_placeholder.subheader(doc_filename)\n",
        "    sidebar_placeholder.write(documents[0].get_text()[:10000]+'...')\n",
        "\n",
        "if index != None:\n",
        "    st.text_input(\"Ask something: \", key='prompt')\n",
        "    st.button(\"Send\", on_click=send_click)\n",
        "    if st.session_state.response:\n",
        "        st.subheader(\"Response: \")\n",
        "        st.success(st.session_state.response, icon= \"🤖\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmnrWzoqBxWD",
        "outputId": "2ac84230-5e7d-4964-b2f2-41da16855be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-06-12 19:48:56.441 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
            "2023-06-12 19:48:56.624 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExcVu2s3Jbhl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd7YDvg6RB4eYpjXDs6aT5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}